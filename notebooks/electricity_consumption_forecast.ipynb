{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234c556-bb48-451b-98de-4952491000f4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from forecaster.scalers import *\n",
    "from forecaster.preprocessing import TimeseriesDataSet, Granularity\n",
    "from forecaster.models import *\n",
    "from forecaster.training import EarlyStopper, ModelTrainer, TimeseriesForecaster\n",
    "from forecaster.evaluation import evaluate_series, top_n_by_metric, get_full_results_dict, align_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "os.makedirs(f\"../logs/mlruns/.trash\", exist_ok=True)\n",
    "torch.cuda.empty_cache()\n",
    "mp.set_start_method('spawn', force=True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff10e8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Data set configuration\n",
    "PATH = \"../data/train_data.csv\" \n",
    "GRANULARITY = Granularity.HOURLY\n",
    "N_SERIES = 137 # Number of parallel time series in the dataset\n",
    "\n",
    "# Model Data configuration\n",
    "SCALER = LogStandardScaler\n",
    "TRAIN_VALIDATION_SPLIT = 0.8\n",
    "INPUT_SIZE = 48\n",
    "OUTPUT_SIZE = 24\n",
    "\n",
    "# Feature toggles\n",
    "USE_TIME_COVARIATES = True  # Include cyclical time covariates in the model inputs\n",
    "\n",
    "# Training configuration\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 512\n",
    "N_EPOCHS = 100\n",
    "\n",
    "# Model configuration\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 4\n",
    "DROPOUT = 0.3\n",
    "# Logging configuration\n",
    "USE_MLFLOW = True\n",
    "SAVE_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d22933e-acca-449b-b428-744d6aadcf46",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "pandas_df = pd.read_csv(PATH)\n",
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit series for faster experimentation\n",
    "pandas_df = pandas_df.iloc[:, :N_SERIES + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1664cf0-89e1-4539-a4a3-d62edf6e32f3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(min(N_SERIES, 10)):  # Plot only first 10 series\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pandas_df[\"deviceTimestamp\"],\n",
    "        y=pandas_df.iloc[:, i + 1],\n",
    "        mode=\"lines\",\n",
    "        name=f\"Value_{i+1}\"\n",
    "    ))\n",
    "fig.update_layout(\n",
    "    title=\"All Series over Time\",\n",
    "    width=1200,\n",
    "    height=400,\n",
    "    xaxis_title=\"deviceTimestamp\",\n",
    "    yaxis_title=\"Value\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeseriesDataSet(pandas_df, GRANULARITY, USE_TIME_COVARIATES, \"deviceTimestamp\", TRAIN_VALIDATION_SPLIT, SCALER, INPUT_SIZE, OUTPUT_SIZE)\n",
    "N_COV = dataset.get_time_feature_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pandas_df.columns[1]  # Select the first series for visualization\n",
    "train_data = dataset.split_scaled_dict[series][\"train\"].flatten()\n",
    "val_data = dataset.split_scaled_dict[series][\"validation\"].flatten()\n",
    "\n",
    "train_idx = np.arange(len(train_data))\n",
    "val_idx = np.arange(len(train_data), len(train_data) + len(val_data))\n",
    "\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Index\": np.concatenate([train_idx, val_idx]),\n",
    "    \"Scaled Value\": np.concatenate([train_data, val_data]),\n",
    "    \"Split\": [\"Train\"] * len(train_data) + [\"Validation\"] * len(val_data)\n",
    "})\n",
    "\n",
    "fig = px.line(\n",
    "    df_plot,\n",
    "    x=\"Index\",\n",
    "    y=\"Scaled Value\",\n",
    "    color=\"Split\",\n",
    "    title=f\"Scaled Data for {series} (Train/Validation Split)\",\n",
    "    width=1200,\n",
    "    height=400\n",
    ")\n",
    "fig.add_vline(x=len(train_data)-1, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Train/Validation Split\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = dataset.split_scaled_dict[\"value_5\"][\"train\"]\n",
    "# print(f\"value_5: mean={data.mean():.3f}, std={data.std():.3f}, \"\n",
    "#         f\"min={data.min():.3f}, max={data.max():.3f}\")\n",
    "# data = dataset.split_scaled_dict[\"value_5\"][\"validation\"]\n",
    "# print(f\"value_5: mean={data.mean():.3f}, std={data.std():.3f}, \"\n",
    "#         f\"min={data.min():.3f}, max={data.max():.3f}\")\n",
    "# data = dataset.split_scaled_dict[\"value_133\"][\"train\"]\n",
    "# print(f\"value_133: mean={data.mean():.3f}, std={data.std():.3f}, \"\n",
    "#         f\"min={data.min():.3f}, max={data.max():.3f}\")\n",
    "# data = dataset.split_scaled_dict[\"value_133\"][\"validation\"]\n",
    "# print(f\"value_133: mean={data.mean():.3f}, std={data.std():.3f}, \"\n",
    "#         f\"min={data.min():.3f}, max={data.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.get_correlation_matrix()\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix of Time Series Values (Sorted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim becomes 1 + N_COV when covariates are used\n",
    "ModelClass = GRU\n",
    "model_params = {\n",
    "    \"input_dim\": 1 + N_COV,\n",
    "    \"hidden_dim\": HIDDEN_DIM,\n",
    "    \"output_dim\": OUTPUT_SIZE,\n",
    "    \"num_layers\": N_LAYERS,\n",
    "    \"dropout\": DROPOUT\n",
    "}\n",
    "model = ModelClass(**model_params)\n",
    "with open(\"../logs/model_architecture.txt\", \"w\") as f:\n",
    "    f.write(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f60fd6-3962-4b6c-81a6-2f0a07e89293",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=15, min_delta=1e-4) # Early stop on thresholded validation loss improvement\n",
    "loss_fn = nn.L1Loss()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "train_loader = dataset.get_train_dataloader(BATCH_SIZE, shuffle=True)\n",
    "val_loader = dataset.get_validation_dataloader(BATCH_SIZE)\n",
    "\n",
    "model_trainer = ModelTrainer(model, DEVICE, optimizer, loss_fn, scheduler, \n",
    "                             train_loader, val_loader,\n",
    "                             early_stopper)\n",
    "\n",
    "def print_metrics(epoch, metrics):\n",
    "    print(f\"Epoch {epoch}: Train RMSE {metrics['train_rmse']:.4f} | Train MAE {metrics['train_mae']:.4f} \\\n",
    "| Val RMSE {metrics['val_rmse']:.4f} | Val MAE {metrics['val_mae']:.4f} | \\\n",
    "LR {metrics['learning_rate']:.6f} | Epoch time {metrics['epoch_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51758343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model_trainer.fit(N_EPOCHS, on_epoch_end=print_metrics)\n",
    "model = model_trainer.get_model()\n",
    "\n",
    "total_training_time = np.sum(history[\"epoch_time\"])\n",
    "epoch_times = history[\"epoch_time\"]\n",
    "print(f\"Total training time: {total_training_time:.2f}s ({total_training_time/60:.2f}m). Avg epoch time: {np.mean(epoch_times):.2f}s\")\n",
    "\n",
    "torch.save(model.state_dict(), \"../logs/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0096f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.eval()\n",
    "except:\n",
    "    model = ModelClass(**model_params)\n",
    "    model.load_state_dict(torch.load(\"../logs/model.pt\", map_location=DEVICE))\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf13752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention heatmap over validation set: rows=lag, cols=windows, colors=attention weights\n",
    "model.eval()\n",
    "key = pandas_df.columns[1]\n",
    "\n",
    "if isinstance(model, (GRUAttention, LSTMAttention)):\n",
    "    with torch.no_grad():\n",
    "        val_dataloader = dataset.get_single_series_dataloader(key, \"validation\", BATCH_SIZE, shuffle=False)\n",
    "        seq_len = dataset.input_size\n",
    "        A_list = []\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            inputs = X_batch.to(DEVICE)\n",
    "            _, attn_weights = model(inputs, return_attention=True)\n",
    "            A_list.append(attn_weights.cpu().numpy())\n",
    "        A = np.vstack(A_list)  # shape (n_windows, seq_len)\n",
    "        # timestamps for validation range\n",
    "        val_timestamps = dataset.get_resampled_data()[dataset.timestamp_column].iloc[dataset.n_train:].reset_index(drop=True)\n",
    "        # map attention windows into heatmap matrix M (rows = window index, cols = validation timestamps)\n",
    "        n_windows = 0 if A.size == 0 else A.shape[0]\n",
    "        M = np.full((n_windows, len(val_timestamps)), np.nan)\n",
    "        for w in range(n_windows):\n",
    "            end_col = min(w + seq_len, len(val_timestamps))\n",
    "            M[w, w:end_col] = A[w, : end_col - w]\n",
    "\n",
    "    # Limit to last week of validation timestamps\n",
    "    if GRANULARITY == Granularity.HOURLY:\n",
    "        last_week_mask = val_timestamps >= (val_timestamps.max() - pd.Timedelta(days=7))\n",
    "    elif GRANULARITY == Granularity.DAILY:\n",
    "        last_week_mask = val_timestamps >= (val_timestamps.max() - pd.Timedelta(days=7))\n",
    "    elif GRANULARITY == Granularity.MONTHLY:\n",
    "        last_week_mask = val_timestamps >= (val_timestamps.max() - pd.DateOffset(months=1))\n",
    "    else:\n",
    "        last_week_mask = np.ones(len(val_timestamps), dtype=bool)\n",
    "    last_week_mask = last_week_mask.values.astype(bool)\n",
    "    val_timestamps = val_timestamps[last_week_mask].reset_index(drop=True)\n",
    "    M = M[:, last_week_mask]\n",
    "    valid_row_mask = ~np.all(np.isnan(M), axis=1)\n",
    "    M = M[valid_row_mask, :]\n",
    "\n",
    "    # get values of series for the last week\n",
    "    series_values = dataset.get_scaled_data(key)[\"validation\"]\n",
    "    series_values = series_values[last_week_mask].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model, (GRUAttention, LSTMAttention)):\n",
    "    fig_heat = go.Figure()\n",
    "\n",
    "    # Heatmap\n",
    "    fig_heat.add_trace(go.Heatmap(\n",
    "        z=M,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Attention'),\n",
    "        x=val_timestamps,\n",
    "        y=list(range(M.shape[0])),\n",
    "        name='attention'\n",
    "    ))\n",
    "\n",
    "    # Series line on a secondary y-axis so it uses its own value scale\n",
    "    fig_heat.add_trace(go.Scatter(\n",
    "        x=val_timestamps,\n",
    "        y=series_values,\n",
    "        mode='lines',\n",
    "        name=f'{key} values',\n",
    "        line=dict(color='black', width=2),\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "\n",
    "    # Layout: add yaxis2 that overlays the heatmap y-axis\n",
    "    fig_heat.update_layout(\n",
    "        title='Attention heatmap for value_35 (timestamps on x-axis, rows=rolling windows)',\n",
    "        xaxis=dict(title='Timestamp (validation range)'),\n",
    "        yaxis=dict(title='Validation window index (rolling)'),\n",
    "        yaxis2=dict(\n",
    "            title=f'Scaled values for {key}',\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n",
    "    )\n",
    "\n",
    "    fig_heat.show()\n",
    "    fig_heat.write_html(\"../logs/attention_heatmap.html\", include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458d1f5-166e-4981-87cc-25f1729b82e0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Train-Validation RMSE Plot (linear + log scale)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history[\"train_rmse\"], marker='o', label='Train RMSE')\n",
    "axes[0].plot(history[\"val_rmse\"], marker='x', label='Val RMSE')\n",
    "axes[0].set_title('RMSE over Epochs (linear)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, which='both', alpha=0.3)\n",
    "\n",
    "axes[1].plot(history[\"train_rmse\"], marker='o', label='Train RMSE')\n",
    "axes[1].plot(history[\"val_rmse\"], marker='x', label='Val RMSE')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_title('RMSE over Epochs (log scale)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('RMSE (log)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../logs/rmse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbf3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(epoch_times, marker='o')\n",
    "plt.axhline(y=np.mean(epoch_times), color='r', linestyle='--', label='Avg Epoch Time')\n",
    "plt.legend()\n",
    "plt.title('Epoch Times')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../logs/epoch_times.png\", bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7f944-0131-4616-b06f-146cbc5480fe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = TimeseriesForecaster(model, DEVICE, INPUT_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "print(\"Generating predictions for all series...\")\n",
    "start_time = time.time()\n",
    "predictions_dict = forecaster.predict_all_series(dataset, BATCH_SIZE)\n",
    "print(f\"Predictions generated in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "summary = evaluate_series(\n",
    "    dataset=dataset,\n",
    "    preds=predictions_dict,\n",
    "    input_size=INPUT_SIZE,\n",
    "    output_size=OUTPUT_SIZE\n",
    ")\n",
    "\n",
    "top_5 = top_n_by_metric(summary, n=5, metric='val_mae', reverse=False)\n",
    "bottom_5 = top_n_by_metric(summary, n=5, metric='val_mae', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_predictions_dict(dataset, input_size, output_size):\n",
    "    naive_preds = {}\n",
    "    for key in dataset.split_unscaled_dict:\n",
    "        naive_preds[key] = {}\n",
    "        for split in ['train', 'validation']:\n",
    "            data = dataset.get_unscaled_data(key)[split]\n",
    "            preds = []\n",
    "            # Match LSTM stride logic\n",
    "            valid_split_points = range(input_size, len(data) + 1, output_size)\n",
    "            for i in valid_split_points:\n",
    "                if i - output_size >= 0:\n",
    "                    pred_window = data[i - output_size : i]\n",
    "                    if len(pred_window) == output_size:\n",
    "                        preds.append(pred_window)\n",
    "            \n",
    "            if preds:\n",
    "                naive_preds[key][split] = np.concatenate(preds).flatten()\n",
    "            else:\n",
    "                naive_preds[key][split] = np.array([])\n",
    "    return naive_preds\n",
    "\n",
    "naive_predictions_dict = get_naive_predictions_dict(dataset, INPUT_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "naive_summary = evaluate_series(\n",
    "    dataset=dataset,\n",
    "    preds=naive_predictions_dict,\n",
    "    input_size=INPUT_SIZE,\n",
    "    output_size=OUTPUT_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Top 5 series by val_mae:\")\n",
    "for k in top_5:\n",
    "    val = summary[k].get('val_mae', np.nan)\n",
    "    print(k, f\"{float(val):.2f}\")\n",
    "print(\"Bottom 5 series by val_mae:\")\n",
    "for k in bottom_5:\n",
    "    val = summary[k].get('val_mae', np.nan)\n",
    "    print(k, f\"{float(val):.2f}\")\n",
    "\n",
    "full_results_dict = get_full_results_dict(dataset, predictions_dict, INPUT_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "# Plot MAE for all series (validation set), sorted by MAE\n",
    "mae_vals = [float(summary[k]['val_mae']) for k in summary]\n",
    "series_names = list(summary.keys())\n",
    "\n",
    "# Sort by MAE\n",
    "sorted_indices = np.argsort(mae_vals)\n",
    "sorted_mae = [mae_vals[i] for i in sorted_indices]\n",
    "sorted_series = [series_names[i] for i in sorted_indices]\n",
    "\n",
    "fig = px.bar(\n",
    "    x=sorted_series,\n",
    "    y=sorted_mae,\n",
    "    labels={\"x\": \"Series\", \"y\": \"Validation MAE\"},\n",
    "    title=\"Validation MAE for All Series (Sorted)\",\n",
    "    width=1200,\n",
    "    height=400\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=90)\n",
    "fig.write_html(\"../logs/all_series_mae_sorted.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45339c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MAPE for all series (validation set), sorted by MAPE\n",
    "mape_vals = [\n",
    "    float(summary[k]['val_mae']) / np.mean(dataset.get_unscaled_data(k)['validation'])\n",
    "    if np.mean(dataset.get_unscaled_data(k)['validation']) != 0 else np.nan\n",
    "    for k in summary\n",
    "]\n",
    "\n",
    "sorted_indices = np.argsort(mape_vals)\n",
    "sorted_mape = [mape_vals[i] for i in sorted_indices]\n",
    "sorted_series = [series_names[i] for i in sorted_indices]\n",
    "\n",
    "fig = px.bar(\n",
    "    x=sorted_series,\n",
    "    y=sorted_mape,\n",
    "    labels={\"x\": \"Series\", \"y\": \"Validation MAPE\"},\n",
    "    title=\"Validation MAPE for All Series (Sorted)\",\n",
    "    width=1200,\n",
    "    height=400\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=90)\n",
    "fig.write_html(\"../logs/all_series_mape_sorted.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663a7c0-7e74-454e-952a-3b07a9878a03",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Unscaled predictions plot\n",
    "top_flop = {**top_5, **bottom_5}\n",
    "\n",
    "for series_key in top_flop:\n",
    "    full_results_df = full_results_dict[series_key]\n",
    "    naive_results_df = naive_predictions_dict[series_key]\n",
    "    \n",
    "    train_mask = ~pd.isna(full_results_df['train_predicted'])\n",
    "    validation_mask = ~pd.isna(full_results_df['validation_predicted'])\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=full_results_df['timestamp'], \n",
    "        y=full_results_df['actual'], \n",
    "        mode='lines', \n",
    "        name='Actual consumption', \n",
    "        line=dict(color='blue', width=1)\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=full_results_df.loc[validation_mask, 'timestamp'], \n",
    "        y=full_results_df.loc[validation_mask, 'validation_predicted'], \n",
    "        mode='lines', \n",
    "        name='Validation predictions', \n",
    "        line=dict(color='red', width=2)\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=full_results_df.loc[validation_mask, 'timestamp'], \n",
    "        y=naive_results_df['validation'], \n",
    "        mode='lines', \n",
    "        name='Naive predictions', \n",
    "        line=dict(color='green', width=1, dash='dot')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f'Electricity Consumption Forecast - Series {series_key}',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Electricity Consumption in Wh',\n",
    "        width=1200, \n",
    "        height=600,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    fig.write_html(f\"../logs/train_validation_truth_{series_key}.html\", include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d9627-2215-4613-9f6e-7a638fb66897",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Results DataFrame for analysis\n",
    "results_dict = {}\n",
    "\n",
    "for series_key in top_flop:\n",
    "    df = full_results_dict[series_key]\n",
    "    validation_mask = ~pd.isna(df['validation_predicted'])\n",
    "    \n",
    "    validation_indices = df.index[validation_mask]\n",
    "    validation_start = validation_indices.min()\n",
    "    validation_end = validation_indices.max() + 1\n",
    "    \n",
    "    # Create results dataframe for each series\n",
    "    results_df = pd.DataFrame({\n",
    "        'timestamp': dataset.get_resampled_data()['deviceTimestamp'].iloc[validation_start:validation_end].reset_index(drop=True),\n",
    "        'actual': df.loc[validation_start:validation_end-1, 'actual'].values,\n",
    "        'predicted': df.loc[validation_start:validation_end-1, 'validation_predicted'].values\n",
    "    })\n",
    "    \n",
    "    if GRANULARITY == Granularity.HOURLY:\n",
    "        results_df['hour_of_day'] = results_df['timestamp'].dt.hour\n",
    "        results_df['day_of_week'] = results_df['timestamp'].dt.day_name()\n",
    "        results_df['month_of_year'] = results_df['timestamp'].dt.month\n",
    "    elif GRANULARITY == Granularity.DAILY:\n",
    "        results_df['day_of_week'] = results_df['timestamp'].dt.day_name()\n",
    "        results_df['month_of_year'] = results_df['timestamp'].dt.month\n",
    "    elif GRANULARITY == Granularity.MONTHLY:\n",
    "        results_df['month_of_year'] = results_df['timestamp'].dt.month\n",
    "    \n",
    "    results_dict[series_key] = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    (\"hour_of_day\", list(range(24)), \"Hour of Day\"),\n",
    "    (\"day_of_week\", ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], \"Day of Week\"),\n",
    "    (\"month_of_year\", list(range(1, 13)), \"Month of Year\")\n",
    "]\n",
    "\n",
    "for col_name, labels, xlab in metrics:\n",
    "    if col_name not in next(iter(results_dict.values())).columns:\n",
    "        continue\n",
    "\n",
    "    n = len(top_flop)\n",
    "    cols = min(5, n)\n",
    "    rows = 2 if n > 5 else 1\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows), squeeze=False)\n",
    "\n",
    "    for idx, series_key in enumerate(top_flop):\n",
    "        ax = axes[idx//cols][idx%cols]\n",
    "        df = results_dict[series_key]\n",
    "\n",
    "        vals = []\n",
    "        for lab in labels:\n",
    "            data = df[df[col_name] == lab]\n",
    "            if not data.empty:\n",
    "                rmse = np.sqrt(np.mean((data[\"actual\"] - data[\"predicted\"])**2))\n",
    "            else:\n",
    "                rmse = np.nan\n",
    "            vals.append(rmse)\n",
    "        ax.bar(labels, vals, alpha=0.7)\n",
    "        ax.set_title(f\"Series {series_key}\")\n",
    "        ax.set_xlabel(xlab)\n",
    "        ax.set_ylabel(\"RMSE\")\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"../logs/rmse_by_{col_name}.svg\", dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric_comparison = {}\n",
    "model_vs_naive = []\n",
    "\n",
    "for series_key in predictions_dict:\n",
    "    if series_key not in naive_summary:\n",
    "        continue\n",
    "\n",
    "    model_metrics = summary[series_key]\n",
    "    naive_metrics = naive_summary[series_key]\n",
    "\n",
    "    metric_comparison[series_key] = {\n",
    "        \"naive_rmse\": float(naive_metrics[\"val_rmse\"]),\n",
    "        \"naive_mae\": float(naive_metrics[\"val_mae\"]),\n",
    "        \"model_rmse\": float(model_metrics[\"val_rmse\"]),\n",
    "        \"model_mae\": float(model_metrics[\"val_mae\"])\n",
    "    }\n",
    "\n",
    "    model_vs_naive.append({\n",
    "        \"series\": series_key,\n",
    "        \"naive_rmse\": naive_metrics[\"val_rmse\"],\n",
    "        \"model_rmse\": model_metrics[\"val_rmse\"],\n",
    "        \"improved\": model_metrics[\"val_rmse\"] < naive_metrics[\"val_rmse\"]\n",
    "    })\n",
    "\n",
    "naive_df = pd.DataFrame.from_dict(metric_comparison, orient=\"index\")\n",
    "naive_df = naive_df.sort_values(\"naive_rmse\")\n",
    "\n",
    "print(\"Overall averages:\")\n",
    "mean_val = np.mean([dataset.get_unscaled_data(k)['validation'].mean() for k in predictions_dict])\n",
    "print(f\"Average time series value over all series: {mean_val:.2f}\")\n",
    "print(f\" Naive RMSE: {naive_df['naive_rmse'].mean():.2f}, Model RMSE: {naive_df['model_rmse'].mean():.2f}\")\n",
    "print(f\" Naive MAE:  {naive_df['naive_mae'].mean():.2f}, Model MAE:  {naive_df['model_mae'].mean():.2f}\")\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "naive_mape = (naive_df['naive_mae'].mean() / mean_val)\n",
    "model_mape = (naive_df['model_mae'].mean() / mean_val)\n",
    "print(f\"MAPE: Naive {naive_mape:.2f}, Model {model_mape:.2f}\")\n",
    "\n",
    "val_mase = naive_df['model_mae'].mean() / naive_df['naive_mae'].mean()\n",
    "print(f\"Model MASE: {val_mase:.2f}\")\n",
    "\n",
    "# Scatter plot: naive vs model mae per series\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.scatter(naive_df[\"naive_mae\"], naive_df[\"model_mae\"], alpha=0.6)\n",
    "ax.plot([naive_df[\"naive_mae\"].min(), naive_df[\"naive_mae\"].max()],\n",
    "        [naive_df[\"naive_mae\"].min(), naive_df[\"naive_mae\"].max()], 'r--', label=\"y=x\",)\n",
    "x_min, x_max = naive_df[\"naive_mae\"].min(), naive_df[\"naive_mae\"].max()\n",
    "xs = np.array([x_min, x_max])\n",
    "ax.plot(xs, val_mase * xs, 'g--', label=f\"y={val_mase:.2f}x\")\n",
    "ax.set_xlabel(\"Naive MAE\")\n",
    "ax.set_ylabel(\"Model MAE\")\n",
    "ax.set_title(\"Model vs Naive MAE per Series\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../logs/naive_vs_model_mae.svg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53142e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series properties and detailed metrics calculation\n",
    "series_props = {}\n",
    "for k in predictions_dict:\n",
    "    # 1. Get Full Unscaled Validation Data\n",
    "    full_val = dataset.get_unscaled_data(k)[\"validation\"]\n",
    "    \n",
    "    # 2. Align Ground Truth using the specific striding logic\n",
    "    y_true = align_ground_truth(full_val, INPUT_SIZE, OUTPUT_SIZE)\n",
    "    \n",
    "    # 3. Get Preds (these are already aligned by the predict method)\n",
    "    y_pred = predictions_dict[k][\"validation\"]\n",
    "    \n",
    "    # 4. Get Naive Metrics (from previous cell calculations)\n",
    "    # We rely on the pre-calculated MAE/RMSE from Cell 24 to avoid re-generating Naive arrays here\n",
    "    naive_mae = metric_comparison[k][\"naive_mae\"] if k in metric_comparison else np.nan\n",
    "    naive_rmse = metric_comparison[k][\"naive_rmse\"] if k in metric_comparison else np.nan\n",
    "\n",
    "    # Properties calculation (on the full original series for context)\n",
    "    s = pd.Series(full_val.flatten())\n",
    "    mean = s.mean()\n",
    "    std = s.std()\n",
    "    coeff_var = std / mean if mean != 0 else np.nan\n",
    "    median = s.median()\n",
    "    mean_abs = np.mean(np.abs(s))\n",
    "    maxv, minv = s.max(), s.min()\n",
    "    skewness = s.skew()\n",
    "    kurt = s.kurtosis()\n",
    "    pct_zero = (s == 0).mean() if len(s) > 0 else np.nan\n",
    "    \n",
    "    try:\n",
    "        if GRANULARITY == Granularity.HOURLY:\n",
    "            autocorr = s.autocorr(lag=24)\n",
    "        elif GRANULARITY == Granularity.DAILY:\n",
    "            autocorr = s.autocorr(lag=7)\n",
    "        else:\n",
    "            autocorr = np.nan\n",
    "    except Exception:\n",
    "        autocorr = np.nan\n",
    "\n",
    "    # Compute Detailed KPIs (R2, Bias, MAPE) on the ALIGNED windows\n",
    "    # Note: y_true and y_pred are now flattened arrays of valid windows\n",
    "    if len(y_true) == len(y_pred) and len(y_true) > 0:\n",
    "        model_mae = float(mean_absolute_error(y_true, y_pred))\n",
    "        model_rmse = float(root_mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        # Mask zeros for MAPE\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            mape_arr = np.abs((y_true - y_pred) / y_true)\n",
    "            mape_arr = mape_arr[np.isfinite(mape_arr)]\n",
    "        model_mape = float(np.mean(mape_arr)) * 100 if len(mape_arr) > 0 else np.nan\n",
    "        \n",
    "        model_r2 = float(r2_score(y_true, y_pred)) if len(y_true) > 1 else np.nan\n",
    "        bias = float(np.mean(y_pred - y_true))\n",
    "    else:\n",
    "        model_mae = model_rmse = model_mape = model_r2 = bias = np.nan\n",
    "\n",
    "    # Per-series MASE\n",
    "    per_mase = model_mae / naive_mae if (naive_mae and not np.isnan(naive_mae) and naive_mae != 0) else np.nan\n",
    "    mae_reduction_pct = (naive_mae - model_mae) / naive_mae * 100 if (naive_mae and naive_mae != 0 and not np.isnan(naive_mae)) else np.nan\n",
    "\n",
    "    series_props[k] = {\n",
    "        \"mean\": mean,\n",
    "        \"std\": std,\n",
    "        \"cv\": coeff_var,\n",
    "        \"median\": median,\n",
    "        \"mean_abs\": mean_abs,\n",
    "        \"max\": maxv,\n",
    "        \"min\": minv,\n",
    "        \"skew\": skewness,\n",
    "        \"kurtosis\": kurt,\n",
    "        \"pct_zero\": pct_zero,\n",
    "        \"autocorr\": autocorr,\n",
    "        \"model_mae\": model_mae,\n",
    "        \"model_rmse\": model_rmse,\n",
    "        \"model_mape_pct\": model_mape,\n",
    "        \"model_r2\": model_r2,\n",
    "        \"model_bias\": bias,\n",
    "        \"naive_mae\": naive_mae,\n",
    "        \"naive_rmse\": naive_rmse,\n",
    "        \"per_mase\": per_mase,\n",
    "        \"mae_reduction_pct\": mae_reduction_pct,\n",
    "        \"n_val\": len(y_true)\n",
    "    }\n",
    "\n",
    "df_stats = pd.DataFrame.from_dict(series_props, orient=\"index\")\n",
    "\n",
    "# Save CSV\n",
    "os.makedirs(\"../logs\", exist_ok=True)\n",
    "df_stats.to_csv(\"../logs/series_stats.csv\")\n",
    "\n",
    "# ... (Rest of the plotting code in this cell remains the same) ...\n",
    "# Plots: scatter property vs model/naive MAE, and improvement\n",
    "plot_cols = [(\"mean\", \"Mean\"), (\"std\", \"Std Dev\"), (\"cv\", \"Coeff of Var\"), (\"mean_abs\", \"Mean Abs (magnitude)\"), (\"autocorr\", \"Seasonal autocorr\")]\n",
    "for col, label in plot_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(data=df_stats, x=col, y=\"model_mae\", label=\"Model MAE\", alpha=0.7)\n",
    "    sns.scatterplot(data=df_stats, x=col, y=\"naive_mae\", label=\"Naive MAE\", alpha=0.6)\n",
    "    plt.xlabel(label); plt.ylabel(\"MAE\"); plt.title(f\"{label} vs MAE (model vs naive)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../logs/{col}_vs_mae.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Plot improvement (percentage) vs properties\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(data=df_stats, x=\"mean_abs\", y=\"mae_reduction_pct\", hue=\"model_r2\", palette=\"viridis\", alpha=0.8)\n",
    "plt.axhline(0, color=\"r\", linestyle=\"--\", label=\"no improvement\")\n",
    "plt.xlabel(\"Mean Abs (magnitude)\"); plt.ylabel(\"MAE reduction vs naive (%)\")\n",
    "plt.title(\"MAE reduction (%) vs Series magnitude\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../logs/mae_reduction_vs_magnitude.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Distribution of per-series MASE and MAE reduction\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df_stats[\"per_mase\"].dropna(), bins=30, kde=False)\n",
    "plt.title(\"Per-series MASE (model / naive)\")\n",
    "plt.xlabel(\"MASE\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df_stats[\"mae_reduction_pct\"].dropna(), bins=30, kde=False)\n",
    "plt.title(\"MAE reduction (%) (naive -> model)\")\n",
    "plt.xlabel(\"% reduction\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../logs/mase_and_reduction_hist.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap between properties and KPIs\n",
    "corr_cols = [\"mean\",\"std\",\"cv\",\"mean_abs\",\"autocorr\",\"model_mae\",\"model_rmse\",\"model_mape_pct\",\"model_r2\",\"model_bias\",\"naive_mae\",\"per_mase\",\"mae_reduction_pct\"]\n",
    "corr = df_stats[corr_cols].corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\", center=0)\n",
    "plt.title(\"Correlation between series properties and KPIs\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../logs/props_kpis_correlation.svg\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Summary counts: how many series improved vs worsened\n",
    "improved = (df_stats[\"mae_reduction_pct\"] > 0).sum()\n",
    "worsened = (df_stats[\"mae_reduction_pct\"] <= 0).sum()\n",
    "print(f\"Series improved vs naive (by MAE): {improved} improved / {len(df_stats)} total ({improved/len(df_stats):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7299893",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Logging with MLFlow\n",
    "if USE_MLFLOW:\n",
    "    mlflow.set_tracking_uri(\"file:../logs/mlruns\")\n",
    "    try:\n",
    "        mlflow.create_experiment(\"Energy_Consumption_Forecast\")\n",
    "    except:\n",
    "        mlflow.set_experiment(\"Energy_Consumption_Forecast\")\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Model Architecture\n",
    "        if SAVE_MODEL:\n",
    "            mlflow.pytorch.log_model(model, name=\"LSTM forecaster\")\n",
    "        \n",
    "        mlflow.log_artifact(\"../logs/model_architecture.txt\")\n",
    "        mlflow.log_param(\"granularity\", GRANULARITY.value)\n",
    "        mlflow.log_param(\"input_size\", INPUT_SIZE)\n",
    "        mlflow.log_param(\"output_size\", OUTPUT_SIZE)\n",
    "        mlflow.log_param(\"learning_rate\", LR)\n",
    "        mlflow.log_param(\"loss_function\", loss_fn._get_name())\n",
    "        mlflow.log_param(\"scaler\", SCALER.__name__)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"n_epochs\", N_EPOCHS)\n",
    "        mlflow.log_param(\"model_type\", ModelClass.__name__)\n",
    "        mlflow.log_param(\"N_SERIES\", N_SERIES)\n",
    "        mlflow.log_param(\"USE_TIME_COVARIATES\", USE_TIME_COVARIATES)\n",
    "\n",
    "        # Model training results\n",
    "        mlflow.log_metric(\"train_rmse\", history[\"train_rmse\"][-1])\n",
    "        mlflow.log_metric(\"train_mae\", history[\"train_mae\"][-1])\n",
    "        mlflow.log_metric(\"train_mae_avg\", np.mean([m['train_mae'] for m in summary.values() if not np.isnan(m['train_mae'])]))\n",
    "        mlflow.log_metric(\"val_mase\", val_mase)\n",
    "        v1 = summary.get(\"value_1\", {})\n",
    "        v1_train_mae = v1.get(\"train_mae\", np.nan)\n",
    "        v1_val_mae = v1.get(\"val_mae\", np.nan)\n",
    "        if not np.isnan(v1_train_mae):\n",
    "            mlflow.log_metric(\"value_1_train_mae\", float(v1_train_mae))\n",
    "        if not np.isnan(v1_val_mae):\n",
    "            mlflow.log_metric(\"value_1_val_mae\", float(v1_val_mae))\n",
    "        mlflow.log_metric(\"val_rmse\", history[\"val_rmse\"][-1])\n",
    "        mlflow.log_metric(\"val_mae\", history[\"val_mae\"][-1])\n",
    "        mlflow.log_metric(\"val_mae_avg\", np.mean([m['val_mae'] for m in summary.values() if not np.isnan(m['val_mae'])]))\n",
    "        mlflow.log_metric(\"total_training_time_sec\", total_training_time)\n",
    "        mlflow.log_artifact(\"../logs/rmse.png\")\n",
    "        mlflow.log_artifact(\"../logs/epoch_times.png\")\n",
    "        mlflow.log_artifact(\"../logs/attention_heatmap.html\")\n",
    "\n",
    "        # Log all series prediction results\n",
    "        if 'hour_of_day' in next(iter(results_dict.values())).columns:\n",
    "            mlflow.log_artifact(f\"../logs/rmse_by_hour_of_day.png\")\n",
    "        if 'day_of_week' in next(iter(results_dict.values())).columns:\n",
    "            mlflow.log_artifact(f\"../logs/rmse_by_day_of_week.png\")\n",
    "        if 'month_of_year' in next(iter(results_dict.values())).columns:\n",
    "            mlflow.log_artifact(f\"../logs/rmse_by_month_of_year.png\")\n",
    "        \n",
    "        for series_key in top_flop:\n",
    "            mlflow.log_artifact(f\"../logs/train_validation_truth_{series_key}.html\")\n",
    "\n",
    "        mlflow.log_artifact(\"../logs/all_series_mae_sorted.html\")\n",
    "        mlflow.log_artifact(\"../logs/all_series_mape_sorted.html\")\n",
    "        mlflow.log_artifact(\"../logs/naive_vs_model_mae.png\")\n",
    "\n",
    "        mlflow.log_artifact(\"../logs/series_stats.csv\")\n",
    "        for col, _ in plot_cols:\n",
    "            mlflow.log_artifact(f\"../logs/{col}_vs_mae.png\")\n",
    "        mlflow.log_artifact(\"../logs/mae_reduction_vs_magnitude.png\")\n",
    "        mlflow.log_artifact(\"../logs/mase_and_reduction_hist.png\")\n",
    "        mlflow.log_artifact(\"../logs/props_kpis_correlation.png\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "known_lakehouses": []
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
